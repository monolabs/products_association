{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815ad63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "from scipy.sparse import csr_matrix\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4772da1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2922905, 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "with open('../data/top500_products.pickle', \"rb\") as input_file:\n",
    "    df = pickle.load(input_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e752d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PendragonS\\miniconda3\\envs\\final\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# load data containing order_dow and hod\n",
    "df_temporal = pd.read_csv('../data/orders.csv', index_col=0)\n",
    "df_temporal = df_temporal[['order_dow', 'order_hour_of_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25015c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_dow_0</th>\n",
       "      <th>order_dow_1</th>\n",
       "      <th>order_dow_2</th>\n",
       "      <th>order_dow_3</th>\n",
       "      <th>order_dow_4</th>\n",
       "      <th>order_dow_5</th>\n",
       "      <th>order_dow_6</th>\n",
       "      <th>order_hod_0</th>\n",
       "      <th>order_hod_1</th>\n",
       "      <th>order_hod_2</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hod_14</th>\n",
       "      <th>order_hod_15</th>\n",
       "      <th>order_hod_16</th>\n",
       "      <th>order_hod_17</th>\n",
       "      <th>order_hod_18</th>\n",
       "      <th>order_hod_19</th>\n",
       "      <th>order_hod_20</th>\n",
       "      <th>order_hod_21</th>\n",
       "      <th>order_hod_22</th>\n",
       "      <th>order_hod_23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473747</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254736</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431534</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_dow_0  order_dow_1  order_dow_2  order_dow_3  order_dow_4  \\\n",
       "order_id                                                                    \n",
       "2539329             0            0            1            0            0   \n",
       "2398795             0            0            0            1            0   \n",
       "473747              0            0            0            1            0   \n",
       "2254736             0            0            0            0            1   \n",
       "431534              0            0            0            0            1   \n",
       "\n",
       "          order_dow_5  order_dow_6  order_hod_0  order_hod_1  order_hod_2  \\\n",
       "order_id                                                                    \n",
       "2539329             0            0            0            0            0   \n",
       "2398795             0            0            0            0            0   \n",
       "473747              0            0            0            0            0   \n",
       "2254736             0            0            0            0            0   \n",
       "431534              0            0            0            0            0   \n",
       "\n",
       "          ...  order_hod_14  order_hod_15  order_hod_16  order_hod_17  \\\n",
       "order_id  ...                                                           \n",
       "2539329   ...             0             0             0             0   \n",
       "2398795   ...             0             0             0             0   \n",
       "473747    ...             0             0             0             0   \n",
       "2254736   ...             0             0             0             0   \n",
       "431534    ...             0             1             0             0   \n",
       "\n",
       "          order_hod_18  order_hod_19  order_hod_20  order_hod_21  \\\n",
       "order_id                                                           \n",
       "2539329              0             0             0             0   \n",
       "2398795              0             0             0             0   \n",
       "473747               0             0             0             0   \n",
       "2254736              0             0             0             0   \n",
       "431534               0             0             0             0   \n",
       "\n",
       "          order_hod_22  order_hod_23  \n",
       "order_id                              \n",
       "2539329              0             0  \n",
       "2398795              0             0  \n",
       "473747               0             0  \n",
       "2254736              0             0  \n",
       "431534               0             0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dow one hot\n",
    "enc = OneHotEncoder()\n",
    "df_temporal[[f\"order_dow_{x}\" for x in range(7)]] = enc.fit_transform(df_temporal.loc[:, 'order_dow'].values.reshape((-1, 1))).toarray().astype(np.int8)\n",
    "\n",
    "# hod one hot\n",
    "enc = OneHotEncoder()\n",
    "df_temporal[[f\"order_hod_{x}\" for x in range(24)]] = enc.fit_transform(df_temporal.loc[:, 'order_hour_of_day'].values.reshape((-1, 1))).toarray().astype(np.int8)\n",
    "\n",
    "df_temporal = df_temporal[[col for col in df_temporal.columns if col not in ['order_dow', 'order_hour_of_day']]]\n",
    "df_temporal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3eff420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2922905, 531)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert df_temporal to sparse\n",
    "df_temporal = pd.DataFrame.sparse.from_spmatrix(csr_matrix(df_temporal.values),\n",
    "                                                index=df_temporal.index,\n",
    "                                                columns=df_temporal.columns)\n",
    "\n",
    "# join dataframes without the original dow and hod\n",
    "df = df.join(df_temporal)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033674e",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f5be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(df,\n",
    "                      label_col,\n",
    "                      features=None,\n",
    "                      test_size=0.2,\n",
    "                      valid_size=0.2,\n",
    "                      random_state=None,\n",
    "                      three_way=False\n",
    "                     ):\n",
    "    if features is None:\n",
    "        features = [col for col in df.columns if col != label_col]\n",
    "    X = csr_matrix(df[features].sparse.to_coo())\n",
    "    y = df[label_col].to_numpy()\n",
    "        \n",
    "    if three_way:\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        seeds = rng.integers(10000, size=2)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            random_state=seeds[0], \n",
    "                                                            stratify=y\n",
    "                                                           )\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                              test_size=test_size, \n",
    "                                                              random_state=seeds[1], \n",
    "                                                              stratify=y_train\n",
    "                                                             )\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            random_state=random_state, \n",
    "                                                            stratify=y\n",
    "                                                           )\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a429fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(true, pred):\n",
    "    scores = []\n",
    "    scores.append(accuracy_score(true, pred))\n",
    "    scores.append(precision_score(true, pred))\n",
    "    scores.append(recall_score(true, pred))\n",
    "    scores.append(f1_score(true, pred))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb301483",
   "metadata": {},
   "source": [
    "# Test Run"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d328a24e",
   "metadata": {},
   "source": [
    "col_features = [x for x in df.columns if x != '33120']\n",
    "\n",
    "X = csr_matrix(df[col_features].sparse.to_coo())\n",
    "y = df[['33120']].to_numpy()\n",
    "\n",
    "xgb_params = {'learning_rate': 0.01,\n",
    "              'colsample_bytree': 0.8,\n",
    "              'subsample': 0.8,\n",
    "              'objective': 'binary:logistic',\n",
    "              'scale_pos_weight': len(y[y == 0])/len(y[y == 1]) * 1,\n",
    "              'eval_metric': 'logloss'\n",
    "             }\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "num_boost_round = 100\n",
    "tic = time.process_time()\n",
    "model = xgb.train(xgb_params,\n",
    "                  dtrain,\n",
    "                  num_boost_round=num_boost_round\n",
    "                 )\n",
    "toc = time.process_time()\n",
    "print(f\"elapsed time for {num_boost_round} rounds: {toc-tic}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e53bf577",
   "metadata": {},
   "source": [
    "feature_importances = {}\n",
    "fi_raw = model.get_score(importance_type='gain')\n",
    "\n",
    "for i, col in enumerate(col_features):\n",
    "    try:\n",
    "        feature_importances[col] = fi_raw[f\"f{i}\"]\n",
    "    except:\n",
    "        feature_importances[col] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7a104",
   "metadata": {},
   "source": [
    "## XGB runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e5b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "\n",
    "# features\n",
    "col_dow = [f\"order_dow_{x}\" for x in range(7)]\n",
    "col_hod = [f\"order_hod_{x}\" for x in range(24)]\n",
    "use_dow = False\n",
    "use_hod = False\n",
    "\n",
    "# xgb params\n",
    "xgb_params = {'learning_rate': 0.1,\n",
    "              'colsample_bytree': 1,\n",
    "              'subsample': 1,\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metric': 'logloss'\n",
    "             }\n",
    "\n",
    "# positive class weight multiplier - multiply weight after balanced\n",
    "pos_mult = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e226c64f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training label: 24852...(0/100)\n",
      "[0]\ttrain-logloss:0.68047\tvalid-logloss:0.68093\n",
      "[99]\ttrain-logloss:0.58845\tvalid-logloss:0.58976\n",
      "training label: 13176...(1/100)\n",
      "[0]\ttrain-logloss:0.67849\tvalid-logloss:0.67808\n",
      "[99]\ttrain-logloss:0.57423\tvalid-logloss:0.57570\n",
      "training label: 21137...(2/100)\n",
      "[0]\ttrain-logloss:0.68364\tvalid-logloss:0.68359\n",
      "[99]\ttrain-logloss:0.58883\tvalid-logloss:0.59043\n",
      "training label: 21903...(3/100)\n",
      "[0]\ttrain-logloss:0.68620\tvalid-logloss:0.68627\n",
      "[99]\ttrain-logloss:0.59857\tvalid-logloss:0.59911\n",
      "training label: 47209...(4/100)\n",
      "[0]\ttrain-logloss:0.68068\tvalid-logloss:0.68037\n",
      "[99]\ttrain-logloss:0.55320\tvalid-logloss:0.55383\n",
      "training label: 47766...(5/100)\n",
      "[0]\ttrain-logloss:0.68047\tvalid-logloss:0.68109\n",
      "[99]\ttrain-logloss:0.56767\tvalid-logloss:0.56841\n",
      "training label: 47626...(6/100)\n",
      "[0]\ttrain-logloss:0.68021\tvalid-logloss:0.68155\n",
      "[99]\ttrain-logloss:0.57120\tvalid-logloss:0.57102\n",
      "training label: 16797...(7/100)\n",
      "[0]\ttrain-logloss:0.68187\tvalid-logloss:0.68222\n",
      "[99]\ttrain-logloss:0.58909\tvalid-logloss:0.58996\n",
      "training label: 26209...(8/100)\n",
      "[0]\ttrain-logloss:0.67573\tvalid-logloss:0.67583\n",
      "[99]\ttrain-logloss:0.53919\tvalid-logloss:0.54015\n",
      "training label: 27845...(9/100)\n",
      "[0]\ttrain-logloss:0.68831\tvalid-logloss:0.68748\n",
      "[99]\ttrain-logloss:0.61153\tvalid-logloss:0.61254\n",
      "training label: 27966...(10/100)\n",
      "[0]\ttrain-logloss:0.67950\tvalid-logloss:0.67923\n",
      "[99]\ttrain-logloss:0.56766\tvalid-logloss:0.56873\n",
      "training label: 22935...(11/100)\n",
      "[0]\ttrain-logloss:0.67692\tvalid-logloss:0.67831\n",
      "[99]\ttrain-logloss:0.52215\tvalid-logloss:0.52329\n",
      "training label: 24964...(12/100)\n",
      "[0]\ttrain-logloss:0.67492\tvalid-logloss:0.67509\n",
      "[99]\ttrain-logloss:0.50272\tvalid-logloss:0.50410\n",
      "training label: 45007...(13/100)\n",
      "[0]\ttrain-logloss:0.68332\tvalid-logloss:0.68316\n",
      "[99]\ttrain-logloss:0.55643\tvalid-logloss:0.55720\n",
      "training label: 39275...(14/100)\n",
      "[0]\ttrain-logloss:0.68148\tvalid-logloss:0.68276\n",
      "[99]\ttrain-logloss:0.60152\tvalid-logloss:0.60287\n",
      "training label: 49683...(15/100)\n",
      "[0]\ttrain-logloss:0.68126\tvalid-logloss:0.68217\n",
      "[99]\ttrain-logloss:0.55743\tvalid-logloss:0.55807\n",
      "training label: 28204...(16/100)\n",
      "[0]\ttrain-logloss:0.68327\tvalid-logloss:0.68380\n",
      "[99]\ttrain-logloss:0.60060\tvalid-logloss:0.60236\n",
      "training label: 5876...(17/100)\n",
      "[0]\ttrain-logloss:0.67841\tvalid-logloss:0.67847\n",
      "[99]\ttrain-logloss:0.54381\tvalid-logloss:0.54469\n",
      "training label: 40706...(18/100)\n",
      "[0]\ttrain-logloss:0.68279\tvalid-logloss:0.68367\n",
      "[99]\ttrain-logloss:0.57731\tvalid-logloss:0.57811\n",
      "training label: 8277...(19/100)\n",
      "[0]\ttrain-logloss:0.68426\tvalid-logloss:0.68317\n",
      "[99]\ttrain-logloss:0.57758\tvalid-logloss:0.57748\n",
      "training label: 4920...(20/100)\n",
      "[0]\ttrain-logloss:0.68593\tvalid-logloss:0.68612\n",
      "[99]\ttrain-logloss:0.61649\tvalid-logloss:0.61775\n",
      "training label: 30391...(21/100)\n",
      "[0]\ttrain-logloss:0.67969\tvalid-logloss:0.67948\n",
      "[99]\ttrain-logloss:0.53251\tvalid-logloss:0.53388\n",
      "training label: 45066...(22/100)\n",
      "[0]\ttrain-logloss:0.68424\tvalid-logloss:0.68330\n",
      "[99]\ttrain-logloss:0.58734\tvalid-logloss:0.58858\n",
      "training label: 42265...(23/100)\n",
      "[0]\ttrain-logloss:0.68518\tvalid-logloss:0.68613\n",
      "[99]\ttrain-logloss:0.59351\tvalid-logloss:0.59412\n",
      "training label: 44632...(24/100)\n",
      "[0]\ttrain-logloss:0.67592\tvalid-logloss:0.67732\n",
      "[99]\ttrain-logloss:0.54297\tvalid-logloss:0.54353\n",
      "training label: 49235...(25/100)\n",
      "[0]\ttrain-logloss:0.69102\tvalid-logloss:0.69092\n",
      "[99]\ttrain-logloss:0.64565\tvalid-logloss:0.64731\n",
      "training label: 19057...(26/100)\n",
      "[0]\ttrain-logloss:0.68138\tvalid-logloss:0.68199\n",
      "[99]\ttrain-logloss:0.57626\tvalid-logloss:0.57809\n",
      "training label: 4605...(27/100)\n",
      "[0]\ttrain-logloss:0.68246\tvalid-logloss:0.68138\n",
      "[99]\ttrain-logloss:0.54436\tvalid-logloss:0.54388\n",
      "training label: 21616...(28/100)\n",
      "[0]\ttrain-logloss:0.68554\tvalid-logloss:0.68544\n",
      "[99]\ttrain-logloss:0.59928\tvalid-logloss:0.60032\n",
      "training label: 37646...(29/100)\n",
      "[0]\ttrain-logloss:0.68397\tvalid-logloss:0.68409\n",
      "[99]\ttrain-logloss:0.58732\tvalid-logloss:0.58761\n",
      "training label: 17794...(30/100)\n",
      "[0]\ttrain-logloss:0.68165\tvalid-logloss:0.68031\n",
      "[99]\ttrain-logloss:0.54535\tvalid-logloss:0.54668\n",
      "training label: 27104...(31/100)\n",
      "[0]\ttrain-logloss:0.68324\tvalid-logloss:0.68416\n",
      "[99]\ttrain-logloss:0.56721\tvalid-logloss:0.56724\n",
      "training label: 30489...(32/100)\n",
      "[0]\ttrain-logloss:0.68393\tvalid-logloss:0.68460\n",
      "[99]\ttrain-logloss:0.57823\tvalid-logloss:0.57905\n",
      "training label: 31717...(33/100)\n",
      "[0]\ttrain-logloss:0.67411\tvalid-logloss:0.67384\n",
      "[99]\ttrain-logloss:0.49550\tvalid-logloss:0.49721\n",
      "training label: 27086...(34/100)\n",
      "[0]\ttrain-logloss:0.68868\tvalid-logloss:0.68878\n",
      "[99]\ttrain-logloss:0.62673\tvalid-logloss:0.62695\n",
      "training label: 46979...(35/100)\n",
      "[0]\ttrain-logloss:0.68505\tvalid-logloss:0.68533\n",
      "[99]\ttrain-logloss:0.59871\tvalid-logloss:0.59972\n",
      "training label: 8518...(36/100)\n",
      "[0]\ttrain-logloss:0.67901\tvalid-logloss:0.67929\n",
      "[99]\ttrain-logloss:0.52851\tvalid-logloss:0.52887\n",
      "training label: 44359...(37/100)\n",
      "[0]\ttrain-logloss:0.67611\tvalid-logloss:0.67643\n",
      "[99]\ttrain-logloss:0.51556\tvalid-logloss:0.51697\n",
      "training label: 28985...(38/100)\n",
      "[0]\ttrain-logloss:0.68175\tvalid-logloss:0.68316\n",
      "[99]\ttrain-logloss:0.57145\tvalid-logloss:0.57307\n",
      "training label: 41950...(39/100)\n",
      "[0]\ttrain-logloss:0.68392\tvalid-logloss:0.68352\n",
      "[99]\ttrain-logloss:0.57389\tvalid-logloss:0.57403\n",
      "training label: 26604...(40/100)\n",
      "[0]\ttrain-logloss:0.67853\tvalid-logloss:0.67876\n",
      "[99]\ttrain-logloss:0.57463\tvalid-logloss:0.57571\n",
      "training label: 5077...(41/100)\n",
      "[0]\ttrain-logloss:0.68886\tvalid-logloss:0.68929\n",
      "[99]\ttrain-logloss:0.62403\tvalid-logloss:0.62472\n",
      "training label: 34126...(42/100)\n",
      "[0]\ttrain-logloss:0.67550\tvalid-logloss:0.67545\n",
      "[99]\ttrain-logloss:0.49824\tvalid-logloss:0.49922\n",
      "training label: 22035...(43/100)\n",
      "[0]\ttrain-logloss:0.68291\tvalid-logloss:0.68244\n",
      "[99]\ttrain-logloss:0.55078\tvalid-logloss:0.55180\n",
      "training label: 39877...(44/100)\n",
      "[0]\ttrain-logloss:0.68489\tvalid-logloss:0.68505\n",
      "[99]\ttrain-logloss:0.58589\tvalid-logloss:0.58584\n",
      "training label: 43352...(45/100)\n",
      "[0]\ttrain-logloss:0.67414\tvalid-logloss:0.67535\n",
      "[99]\ttrain-logloss:0.52329\tvalid-logloss:0.52424\n",
      "training label: 35951...(46/100)\n",
      "[0]\ttrain-logloss:0.68557\tvalid-logloss:0.68616\n",
      "[99]\ttrain-logloss:0.60447\tvalid-logloss:0.60486\n",
      "training label: 10749...(47/100)\n",
      "[0]\ttrain-logloss:0.67683\tvalid-logloss:0.67590\n",
      "[99]\ttrain-logloss:0.50324\tvalid-logloss:0.50329\n",
      "training label: 19660...(48/100)\n",
      "[0]\ttrain-logloss:0.69061\tvalid-logloss:0.69075\n",
      "[99]\ttrain-logloss:0.64414\tvalid-logloss:0.64528\n",
      "training label: 9076...(49/100)\n",
      "[0]\ttrain-logloss:0.68328\tvalid-logloss:0.68292\n",
      "[99]\ttrain-logloss:0.58760\tvalid-logloss:0.58930\n",
      "training label: 24184...(50/100)\n",
      "[0]\ttrain-logloss:0.67965\tvalid-logloss:0.67843\n",
      "[99]\ttrain-logloss:0.52426\tvalid-logloss:0.52545\n",
      "training label: 21938...(51/100)\n",
      "[0]\ttrain-logloss:0.67568\tvalid-logloss:0.67631\n",
      "[99]\ttrain-logloss:0.51662\tvalid-logloss:0.51680\n",
      "training label: 43961...(52/100)\n",
      "[0]\ttrain-logloss:0.68603\tvalid-logloss:0.68512\n",
      "[99]\ttrain-logloss:0.59439\tvalid-logloss:0.59514\n",
      "training label: 34969...(53/100)\n",
      "[0]\ttrain-logloss:0.68493\tvalid-logloss:0.68371\n",
      "[99]\ttrain-logloss:0.57524\tvalid-logloss:0.57672\n",
      "training label: 48679...(54/100)\n",
      "[0]\ttrain-logloss:0.67958\tvalid-logloss:0.67933\n",
      "[99]\ttrain-logloss:0.54159\tvalid-logloss:0.54227\n",
      "training label: 46667...(55/100)\n",
      "[0]\ttrain-logloss:0.67703\tvalid-logloss:0.67623\n",
      "[99]\ttrain-logloss:0.52149\tvalid-logloss:0.52229\n",
      "training label: 12341...(56/100)\n",
      "[0]\ttrain-logloss:0.67868\tvalid-logloss:0.67966\n",
      "[99]\ttrain-logloss:0.53608\tvalid-logloss:0.53709\n",
      "training label: 25890...(57/100)\n",
      "[0]\ttrain-logloss:0.68477\tvalid-logloss:0.68459\n",
      "[99]\ttrain-logloss:0.57097\tvalid-logloss:0.57183\n",
      "training label: 31506...(58/100)\n",
      "[0]\ttrain-logloss:0.69090\tvalid-logloss:0.68982\n",
      "[99]\ttrain-logloss:0.64465\tvalid-logloss:0.64540\n",
      "training label: 5450...(59/100)\n",
      "[0]\ttrain-logloss:0.68354\tvalid-logloss:0.68190\n",
      "[99]\ttrain-logloss:0.56477\tvalid-logloss:0.56471\n",
      "training label: 39928...(60/100)\n",
      "[0]\ttrain-logloss:0.68041\tvalid-logloss:0.67964\n",
      "[99]\ttrain-logloss:0.54832\tvalid-logloss:0.54980\n",
      "training label: 24838...(61/100)\n",
      "[0]\ttrain-logloss:0.68816\tvalid-logloss:0.68886\n",
      "[99]\ttrain-logloss:0.62300\tvalid-logloss:0.62359\n",
      "training label: 22825...(62/100)\n",
      "[0]\ttrain-logloss:0.67963\tvalid-logloss:0.67961\n",
      "[99]\ttrain-logloss:0.53876\tvalid-logloss:0.53973\n",
      "training label: 5785...(63/100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68530\tvalid-logloss:0.68484\n",
      "[99]\ttrain-logloss:0.57457\tvalid-logloss:0.57430\n",
      "training label: 35221...(64/100)\n",
      "[0]\ttrain-logloss:0.67042\tvalid-logloss:0.67098\n",
      "[99]\ttrain-logloss:0.50432\tvalid-logloss:0.50460\n",
      "training label: 28842...(65/100)\n",
      "[0]\ttrain-logloss:0.67245\tvalid-logloss:0.67219\n",
      "[99]\ttrain-logloss:0.48136\tvalid-logloss:0.48197\n",
      "training label: 33731...(66/100)\n",
      "[0]\ttrain-logloss:0.68424\tvalid-logloss:0.68553\n",
      "[99]\ttrain-logloss:0.56760\tvalid-logloss:0.56835\n",
      "training label: 8424...(67/100)\n",
      "[0]\ttrain-logloss:0.68070\tvalid-logloss:0.68113\n",
      "[99]\ttrain-logloss:0.54895\tvalid-logloss:0.54961\n",
      "training label: 27521...(68/100)\n",
      "[0]\ttrain-logloss:0.68024\tvalid-logloss:0.68161\n",
      "[99]\ttrain-logloss:0.53845\tvalid-logloss:0.53968\n",
      "training label: 33198...(69/100)\n",
      "[0]\ttrain-logloss:0.69048\tvalid-logloss:0.69060\n",
      "[99]\ttrain-logloss:0.63987\tvalid-logloss:0.64017\n",
      "training label: 8174...(70/100)\n",
      "[0]\ttrain-logloss:0.68018\tvalid-logloss:0.68091\n",
      "[99]\ttrain-logloss:0.55889\tvalid-logloss:0.55944\n",
      "training label: 44142...(71/100)\n",
      "[0]\ttrain-logloss:0.68122\tvalid-logloss:0.68104\n",
      "[99]\ttrain-logloss:0.53676\tvalid-logloss:0.53665\n",
      "training label: 20114...(72/100)\n",
      "[0]\ttrain-logloss:0.67282\tvalid-logloss:0.67215\n",
      "[99]\ttrain-logloss:0.49124\tvalid-logloss:0.49261\n",
      "training label: 27344...(73/100)\n",
      "[0]\ttrain-logloss:0.68686\tvalid-logloss:0.68762\n",
      "[99]\ttrain-logloss:0.59593\tvalid-logloss:0.59629\n",
      "training label: 11520...(74/100)\n",
      "[0]\ttrain-logloss:0.68744\tvalid-logloss:0.68751\n",
      "[99]\ttrain-logloss:0.60377\tvalid-logloss:0.60468\n",
      "training label: 29487...(75/100)\n",
      "[0]\ttrain-logloss:0.68365\tvalid-logloss:0.68333\n",
      "[99]\ttrain-logloss:0.55699\tvalid-logloss:0.55713\n",
      "training label: 18465...(76/100)\n",
      "[0]\ttrain-logloss:0.68503\tvalid-logloss:0.68567\n",
      "[99]\ttrain-logloss:0.58849\tvalid-logloss:0.58920\n",
      "training label: 28199...(77/100)\n",
      "[0]\ttrain-logloss:0.68645\tvalid-logloss:0.68697\n",
      "[99]\ttrain-logloss:0.61890\tvalid-logloss:0.61965\n",
      "training label: 15290...(78/100)\n",
      "[0]\ttrain-logloss:0.67239\tvalid-logloss:0.67141\n",
      "[99]\ttrain-logloss:0.48592\tvalid-logloss:0.48725\n",
      "training label: 46906...(79/100)\n",
      "[0]\ttrain-logloss:0.68451\tvalid-logloss:0.68547\n",
      "[99]\ttrain-logloss:0.58626\tvalid-logloss:0.58731\n",
      "training label: 9839...(80/100)\n",
      "[0]\ttrain-logloss:0.68190\tvalid-logloss:0.68143\n",
      "[99]\ttrain-logloss:0.54645\tvalid-logloss:0.54830\n",
      "training label: 27156...(81/100)\n",
      "[0]\ttrain-logloss:0.68094\tvalid-logloss:0.68086\n",
      "[99]\ttrain-logloss:0.52498\tvalid-logloss:0.52648\n",
      "training label: 3957...(82/100)\n",
      "[0]\ttrain-logloss:0.68750\tvalid-logloss:0.68754\n",
      "[99]\ttrain-logloss:0.61206\tvalid-logloss:0.61288\n",
      "training label: 43122...(83/100)\n",
      "[0]\ttrain-logloss:0.68028\tvalid-logloss:0.67909\n",
      "[99]\ttrain-logloss:0.54061\tvalid-logloss:0.54083\n",
      "training label: 23909...(84/100)\n",
      "[0]\ttrain-logloss:0.68319\tvalid-logloss:0.68377\n",
      "[99]\ttrain-logloss:0.56475\tvalid-logloss:0.56628\n",
      "training label: 34358...(85/100)\n",
      "[0]\ttrain-logloss:0.67916\tvalid-logloss:0.67916\n",
      "[99]\ttrain-logloss:0.50996\tvalid-logloss:0.51131\n",
      "training label: 4799...(86/100)\n",
      "[0]\ttrain-logloss:0.68421\tvalid-logloss:0.68577\n",
      "[99]\ttrain-logloss:0.57491\tvalid-logloss:0.57558\n",
      "training label: 9387...(87/100)\n",
      "[0]\ttrain-logloss:0.68478\tvalid-logloss:0.68560\n",
      "[99]\ttrain-logloss:0.59696\tvalid-logloss:0.59793\n",
      "training label: 16759...(88/100)\n",
      "[0]\ttrain-logloss:0.67915\tvalid-logloss:0.67998\n",
      "[99]\ttrain-logloss:0.53277\tvalid-logloss:0.53266\n",
      "training label: 196...(89/100)\n",
      "[0]\ttrain-logloss:0.67717\tvalid-logloss:0.67623\n",
      "[99]\ttrain-logloss:0.47021\tvalid-logloss:0.47128\n",
      "training label: 42736...(90/100)\n",
      "[0]\ttrain-logloss:0.68660\tvalid-logloss:0.68681\n",
      "[99]\ttrain-logloss:0.58793\tvalid-logloss:0.58970\n",
      "training label: 4210...(91/100)\n",
      "[0]\ttrain-logloss:0.68741\tvalid-logloss:0.68642\n",
      "[99]\ttrain-logloss:0.59948\tvalid-logloss:0.60022\n",
      "training label: 38689...(92/100)\n",
      "[0]\ttrain-logloss:0.68592\tvalid-logloss:0.68520\n",
      "[99]\ttrain-logloss:0.57893\tvalid-logloss:0.58032\n",
      "training label: 41787...(93/100)\n",
      "[0]\ttrain-logloss:0.68059\tvalid-logloss:0.68049\n",
      "[99]\ttrain-logloss:0.56683\tvalid-logloss:0.56679\n",
      "training label: 47144...(94/100)\n",
      "[0]\ttrain-logloss:0.68973\tvalid-logloss:0.68916\n",
      "[99]\ttrain-logloss:0.63242\tvalid-logloss:0.63340\n",
      "training label: 41220...(95/100)\n",
      "[0]\ttrain-logloss:0.68316\tvalid-logloss:0.68395\n",
      "[99]\ttrain-logloss:0.56558\tvalid-logloss:0.56635\n",
      "training label: 7781...(96/100)\n",
      "[0]\ttrain-logloss:0.68601\tvalid-logloss:0.68552\n",
      "[99]\ttrain-logloss:0.56461\tvalid-logloss:0.56500\n",
      "training label: 33000...(97/100)\n",
      "[0]\ttrain-logloss:0.69049\tvalid-logloss:0.68950\n",
      "[99]\ttrain-logloss:0.63259\tvalid-logloss:0.63319\n",
      "training label: 20995...(98/100)\n",
      "[0]\ttrain-logloss:0.68755\tvalid-logloss:0.68655\n",
      "[99]\ttrain-logloss:0.59553\tvalid-logloss:0.59683\n",
      "training label: 21709...(99/100)\n",
      "[0]\ttrain-logloss:0.66896\tvalid-logloss:0.66758\n",
      "[99]\ttrain-logloss:0.48233\tvalid-logloss:0.48274\n",
      "elapsed_time: 44792.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e59159fc48a5>:64: FutureWarning: In a future version of pandas all arguments of DataFrame.set_index except for the argument 'keys' will be keyword-only\n",
      "  feature_importances_df = feature_importances_df.set_index(pd.Index(predicted_products), 'predicted_product')\n"
     ]
    }
   ],
   "source": [
    "# LOOP THROUGH TOP ALL PRODUCTS\n",
    "\n",
    "tic = time.process_time()\n",
    "\n",
    "valid_scores_all = []\n",
    "test_scores_all = []\n",
    "feature_importances_df = pd.DataFrame()\n",
    "\n",
    "predicted_products = df.iloc[:, :500].columns.tolist()\n",
    "\n",
    "for i, label in enumerate(predicted_products):\n",
    "    \n",
    "    print(f\"training label: {label}...({i}/{len(predicted_products)})\")\n",
    "\n",
    "    # DATA SETUP\n",
    "\n",
    "    features = ([x for x in df.columns if x != label])\n",
    "    if not use_dow: features = [f for f in features if f not in col_dow]\n",
    "    if not use_hod: features = [f for f in features if f not in col_hod]\n",
    "\n",
    "    # setup train and test set\n",
    "    df_xgb = df[features + [label]]\n",
    "    X_train, X_valid, y_train, y_valid = partition_dataset(df_xgb, \n",
    "                                                           label,\n",
    "                                                           three_way=False,\n",
    "                                                           random_state=0)\n",
    "\n",
    "    # PARAMS SETUP\n",
    "    xgb_params['scale_pos_weight'] = len(y_train[y_train == 0])/len(y_train[y_train == 1]) * pos_mult\n",
    "        \n",
    "\n",
    "    # TRAINING\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    watchlist = [(dtrain,'train'), (dvalid,'valid')]\n",
    "\n",
    "    model = xgb.train(xgb_params,\n",
    "                      dtrain,\n",
    "                      num_boost_round=100,\n",
    "                      evals=watchlist,\n",
    "                      early_stopping_rounds=20,\n",
    "                      verbose_eval=100)\n",
    "    \n",
    "    # save model\n",
    "    model.save_model(f\"../models/xgb_{label}_v{version}_fi.model\")\n",
    "    \n",
    "    # feature importance\n",
    "    feature_importances = {}\n",
    "    fi_raw = model.get_score(importance_type='gain')\n",
    "    for i, col in enumerate(features):\n",
    "        try:\n",
    "            feature_importances[col] = fi_raw[f\"f{i}\"]\n",
    "        except:\n",
    "            feature_importances[col] = np.nan\n",
    "    feature_importances_df = feature_importances_df.append(feature_importances, ignore_index=True)\n",
    "        \n",
    "    # prediction\n",
    "    pred_valid = (model.predict(dvalid) > 0.5).astype(int)\n",
    "    valid_scores_all.append(classification_scores(y_valid, pred_valid))\n",
    "\n",
    "    \n",
    "# feature importances indexing\n",
    "feature_importances_df = feature_importances_df.set_index(pd.Index(predicted_products), 'predicted_product')\n",
    "feature_importances_df.to_csv(f\"../results/xgb_feature_importances_v{version}_top500.csv\")\n",
    "\n",
    "# final processing of scores\n",
    "df_scores = pd.DataFrame(valid_scores_all,\n",
    "                         columns=['valid_accuracy', 'valid_precision', 'valid_recall', 'valid_f1'],\n",
    "                         index=predicted_products\n",
    "                        )\n",
    "df_scores.to_csv(f\"../results/xgb_product_v{version}_top500.csv\")\n",
    "\n",
    "toc = time.process_time()\n",
    "print(f\"elapsed_time: {toc - tic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d10d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (final)",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
